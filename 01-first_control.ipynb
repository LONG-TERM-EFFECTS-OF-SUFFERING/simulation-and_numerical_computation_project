{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- ---\n",
    "reviewed_on: \"2024-10-11\"\n",
    "--- -->\n",
    "\n",
    "# First control"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the dataset\n",
    "\n",
    "Our dataset is the [CIFAR-10](https://www.cs.toronto.edu/~kriz/cifar.html) dataset consists of $60000$ $32 \\times 32$ color images in $10$ classes, with $6000$ images per class. The classes are:\n",
    "\n",
    "- airplane.\n",
    "\n",
    "- automobile.\n",
    "\n",
    "- bird.\n",
    "\n",
    "- cat.\n",
    "\n",
    "- deer.\n",
    "\n",
    "- dog.\n",
    "\n",
    "- frog.\n",
    "\n",
    "- horse.\n",
    "\n",
    "- ship.\n",
    "\n",
    "- truck."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms\n",
    "\n",
    "\n",
    "# Define a transform to normalize the data\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "\t\t\t\t\t\t\t\ttransforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "\t\t\t\t\t\t\t\t])\n",
    "\n",
    "# Download and load the training data\n",
    "trainset = datasets.CIFAR10(\"~/.pytorch/CIFAR-10/\", download=True, train=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = [\n",
    "\t\t\t\"airplane\",\n",
    "\t\t\t\"automobile\",\n",
    "\t\t\t\"bird\",\n",
    "\t\t\t\"cat\",\n",
    "\t\t\t\"deer\",\n",
    "\t\t\t\"dog\",\n",
    "\t\t\t\"frog\",\n",
    "\t\t\t\"horse\",\n",
    "\t\t\t\"ship\",\n",
    "\t\t\t\"truck\"\n",
    "\t\t]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To check if the dataset is correct, we will check the number of instances per label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "\n",
    "# Extract all labels\n",
    "labels = [label for _, label in trainset]\n",
    "\n",
    "# Count the number of records per label\n",
    "label_counts = Counter(labels)\n",
    "\n",
    "for i, count in label_counts.items():\n",
    "\tprint(f\"{classes[i]}: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataiter = iter(trainloader)\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "print(type(images))\n",
    "print(images.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To display the image we could use `plt.imshow`, but that function expects the image data to have the form `(height, width, channels)`, so to use it we must manipulate the tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = images[0].permute(1, 2, 0).numpy() # Reorder the array and conver it\n",
    "\t\t\t\t\t\t\t\t\t\t # into a numpy array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `plt.imshow` also expects the input range to be in the range of $0$ to $1$, to ensure that we must normalize the image for proper display."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the image to the range [0, 1]\n",
    "img = (img - img.min()) / (img.max() - img.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manual implementation of a neural network\n",
    "\n",
    "In the guide the implemented neural network had $256$ neurons in the hidden layer, so we will create one with the same amount, using the sigmoid activation function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def activation(x):\n",
    "\treturn 1 / (1 + torch.exp(-x))\n",
    "\n",
    "inputs = images.view(images.shape[0], -1) # (64, 3072), 3072 = 3 * 32 * 32\n",
    "\n",
    "W_1 = torch.randn(3072, 256)\n",
    "B_1 = torch.randn(256)\n",
    "\n",
    "W_2 = torch.randn(256, 10)\n",
    "B_2 = torch.randn(10)\n",
    "\n",
    "h = activation(torch.mm(inputs, W_1) + B_1)\n",
    "output = activation(torch.mm(h, W_2) + B_2)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following the guide, now we will calculate the probability distribution using the softmax function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "\treturn torch.exp(x) / torch.sum(torch.exp(x), dim=1).view(-1, 1)\n",
    "\n",
    "probabilities = softmax(output)\n",
    "print(probabilities.shape)\n",
    "print(probabilities.sum(dim=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a neural network with PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "\tdef __init__(self):\n",
    "\t\tsuper().__init__()\n",
    "\n",
    "\t\tself.fc1 = nn.Linear(3072, 128)\n",
    "\t\tself.fc2 = nn.Linear(128, 64)\n",
    "\t\tself.fc3 = nn.Linear(64, 10)\n",
    "\n",
    "\t\tself.ReLU = nn.ReLU()\n",
    "\t\tself.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "\tdef forward(self, x):\n",
    "\t\tx = self.fc1(x)\n",
    "\t\tx = self.ReLU(x)\n",
    "\t\tx = self.fc2(x)\n",
    "\t\tx = self.ReLU(x)\n",
    "\t\tx = self.fc3(x)\n",
    "\t\tx = self.ReLU(x)\n",
    "\t\tx = self.softmax(x)\n",
    "\n",
    "\t\treturn x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Network()\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using `torch.nn.functional`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Network(nn.Module):\n",
    "\tdef __init__(self):\n",
    "\t\tsuper().__init__()\n",
    "\n",
    "\t\tself.fc1 = nn.Linear(3072, 128)\n",
    "\t\tself.fc2 = nn.Linear(128, 64)\n",
    "\t\tself.fc3 = nn.Linear(64, 10)\n",
    "\n",
    "\tdef forward(self, x):\n",
    "\t\t# Hidden layer 1 with ReLu activacion\n",
    "\t\tx = F.relu(self.fc1(x))\n",
    "\t\t# Hidden layer 2 with ReLu activacion\n",
    "\t\tx = F.relu(self.fc2(x))\n",
    "\t\t# Output layer with softmax activacion\n",
    "\t\tx = F.softmax(self.fc3(x), dim=1)\n",
    "\n",
    "\t\treturn x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Network()\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initializing weights and biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fc1.bias.data.fill_(0)\n",
    "model.fc1.weight.data.normal_(std=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forward pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def view_classify(img, ps, classes):\n",
    "\t''' Function for viewing an image and its predicted classes.\n",
    "\t'''\n",
    "\tps = ps.data.numpy().squeeze()\n",
    "\n",
    "\tfig, (ax1, ax2) = plt.subplots(figsize=(6, 9), ncols=2)\n",
    "\timg = img.permute(1, 2, 0) # Reorder the tensor dimensions for plt.imshow\n",
    "\timg = (img - img.min()) / (img.max() - img.min())\n",
    "\tax1.imshow(img.numpy())\n",
    "\tax1.axis('off')\n",
    "\tax2.barh(np.arange(len(classes)), ps)\n",
    "\tax2.set_aspect(0.1)\n",
    "\tax2.set_yticks(np.arange(len(classes)))\n",
    "\tax2.set_yticklabels(classes, size=\"small\")\n",
    "\tax2.set_title(\"Class probability\")\n",
    "\tax2.set_xlim(0, 1.1)\n",
    "\n",
    "\tplt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, labels = next(dataiter)\n",
    "\n",
    "# Reshape images into a 1D vector, new shape is (batch size, 3072)\n",
    "images = images.view(images.shape[0], -1)  # Flatten the images\n",
    "\n",
    "print(images.shape)\n",
    "# Forward pass through the network\n",
    "img_idx = 0\n",
    "img = images[img_idx] # (3072,)\n",
    "ps = model.forward(img.unsqueeze(0)) # Add batch dimension to make it (1, 3072)\n",
    "\n",
    "view_classify(img.view(3, 32, 32), ps, classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using `nn.Sequential`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters for our network\n",
    "input_size = 3072\n",
    "hidden_sizes = [128, 64]\n",
    "output_size = 10\n",
    "\n",
    "# Build a feed-forward network\n",
    "model = nn.Sequential(nn.Linear(input_size, hidden_sizes[0]),\n",
    "\t\t\t\t\t\tnn.ReLU(),\n",
    "\t\t\t\t\t\tnn.Linear(hidden_sizes[0], hidden_sizes[1]),\n",
    "\t\t\t\t\t\tnn.ReLU(),\n",
    "\t\t\t\t\t\tnn.Linear(hidden_sizes[1], output_size),\n",
    "\t\t\t\t\t\tnn.Softmax(dim=1))\n",
    "\n",
    "# Forward pass through the network and display output\n",
    "images, labels = next(dataiter)\n",
    "images = images.view(images.shape[0], -1)\n",
    "img = images[0]\n",
    "ps = model.forward(img.unsqueeze(0))\n",
    "view_classify(img.view(3, 32, 32), ps, classes)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
